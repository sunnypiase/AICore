{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly\n",
    "# !pip install nbformat>=4.2.0\n",
    "# !pip install ipykernel\n",
    "# !pip install --upgrade nbformat\n",
    "# !pip install seaborn\n",
    "# !pip install websocket-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from TraderEnvNormilized import TraderEnvNormalized\n",
    "from DataProvider import DataProvider\n",
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from sb3_contrib import RecurrentPPO\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import gymnasium as gym\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTIPLIER = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "PPO_Path = os.path.join('Training', 'SavedModels', 'PPO_Model_Cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = 'Data/Binance_BTCUSDT_2024_minute.csv'\n",
    "\n",
    "# Load data\n",
    "data_provider = DataProvider(data_file_path)\n",
    "df_raw = data_provider.get_raw_data().dropna()[-1000 * MULTIPLIER:].reset_index(drop=True)\n",
    "df_normalized = data_provider.get_normalized_data().dropna()[-1000 * MULTIPLIER:].reset_index(drop=True)\n",
    "\n",
    "# Initialize the environment\n",
    "trade_env = TraderEnvNormalized(df_raw, df_normalized, trade_size_dollars=9_000, initial_capital=10_000,save_history= False)\n",
    "env = DummyVecEnv([lambda: trade_env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_normalized\n",
    "# data_provider.plot_histograms()\n",
    "# data_provider.plot_histograms_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "n_steps = 1000 * MULTIPLIER #16384\n",
    "n_epochs = 20\n",
    "batch_size = 128 * 2\n",
    "ent_coef = 0.001\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU,\n",
    "                     net_arch=dict(pi=[256, 256, 128, 64], vf=[256, 256, 128, 64]))\n",
    "model = RecurrentPPO(\"MlpLstmPolicy\", env, verbose=1, tensorboard_log=log_path, ent_coef=ent_coef, \n",
    "                     n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs, \n",
    "                     learning_rate=2.5e-4, gamma=0.99, gae_lambda=0.95, vf_coef=0.5, \n",
    "                     max_grad_norm=0.5, clip_range= 0.1, policy_kwargs=policy_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopTrainingOnMaxSteps(BaseCallback):\n",
    "    def __init__(self, max_steps=49999, verbose=0):\n",
    "        super(StopTrainingOnMaxSteps, self).__init__(verbose)\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Access the environment and get current_step\n",
    "        current_step = self.training_env.get_attr(\"current_step\")[0]\n",
    "        sharpe_ratio = self.training_env.get_attr(\"sharpe_ratio\")[0]\n",
    "        if current_step >= self.max_steps:\n",
    "            if sharpe_ratio > 2:\n",
    "                print(\"end with condition\")\n",
    "                return False  # Return False to stop the training\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\RecurrentPPO_79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 345    |\n",
      "|    total_timesteps | 100000 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 989         |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009671675 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.78        |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.000575   |\n",
      "|    value_loss           | 65.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 180         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1659        |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004970399 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.000876   |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 170         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2349        |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007134319 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | 0.000319    |\n",
      "|    value_loss           | 73.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3017        |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004008462 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | 0.000935    |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 162          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 3681         |\n",
      "|    total_timesteps      | 600000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044573047 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 2900         |\n",
      "|    policy_gradient_loss | 0.000632     |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 161          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 4347         |\n",
      "|    total_timesteps      | 700000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046809483 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.17         |\n",
      "|    n_updates            | 2920         |\n",
      "|    policy_gradient_loss | 0.00737      |\n",
      "|    value_loss           | 76.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 4988        |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005012428 |\n",
      "|    clip_fraction        | 0.0272      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.000176   |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 159          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 5646         |\n",
      "|    total_timesteps      | 900000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038532864 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.985       |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.287        |\n",
      "|    n_updates            | 2960         |\n",
      "|    policy_gradient_loss | -0.000261    |\n",
      "|    value_loss           | 88           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 156          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 6405         |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021340435 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 2980         |\n",
      "|    policy_gradient_loss | 0.000109     |\n",
      "|    value_loss           | 47.9         |\n",
      "------------------------------------------\n",
      "Logging to Training\\Logs\\RecurrentPPO_80\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 312    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 320    |\n",
      "|    total_timesteps | 100000 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 190          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1047         |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072920644 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 3020         |\n",
      "|    policy_gradient_loss | 1.71e-05     |\n",
      "|    value_loss           | 58           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 167          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1788         |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064137494 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.987       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 3040         |\n",
      "|    policy_gradient_loss | 0.000783     |\n",
      "|    value_loss           | 74.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 158          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 2529         |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020413413 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 3060         |\n",
      "|    policy_gradient_loss | -6.45e-05    |\n",
      "|    value_loss           | 74.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 3267         |\n",
      "|    total_timesteps      | 500000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049702837 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.11         |\n",
      "|    n_updates            | 3080         |\n",
      "|    policy_gradient_loss | 0.000647     |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 4011       |\n",
      "|    total_timesteps      | 600000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00533736 |\n",
      "|    clip_fraction        | 0.0238     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.76       |\n",
      "|    n_updates            | 3100       |\n",
      "|    policy_gradient_loss | 0.000394   |\n",
      "|    value_loss           | 47.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 147          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 4747         |\n",
      "|    total_timesteps      | 700000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069279047 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.86         |\n",
      "|    n_updates            | 3120         |\n",
      "|    policy_gradient_loss | -0.000302    |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 145          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 5481         |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030538517 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 3140         |\n",
      "|    policy_gradient_loss | 0.00028      |\n",
      "|    value_loss           | 86.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 6232        |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010688682 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.57e+04    |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | 0.000382    |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 143          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 6966         |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061799097 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 3180         |\n",
      "|    policy_gradient_loss | 0.000143     |\n",
      "|    value_loss           | 81.1         |\n",
      "------------------------------------------\n",
      "Logging to Training\\Logs\\RecurrentPPO_81\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 314    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 317    |\n",
      "|    total_timesteps | 100000 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 186          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1071         |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029798714 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 3220         |\n",
      "|    policy_gradient_loss | 0.00035      |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 166        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 1805       |\n",
      "|    total_timesteps      | 300000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00665887 |\n",
      "|    clip_fraction        | 0.0187     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.13       |\n",
      "|    n_updates            | 3240       |\n",
      "|    policy_gradient_loss | 0.00028    |\n",
      "|    value_loss           | 38.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 157          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 2541         |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037254856 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 3260         |\n",
      "|    policy_gradient_loss | 0.000873     |\n",
      "|    value_loss           | 55.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3289        |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007580792 |\n",
      "|    clip_fraction        | 0.00573     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.000264   |\n",
      "|    value_loss           | 62.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4031        |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004353138 |\n",
      "|    clip_fraction        | 0.00665     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | 5.36e-05    |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 4756        |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010498412 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | 0.00124     |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 5512        |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009507307 |\n",
      "|    clip_fraction        | 0.007       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.66        |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | 0.000141    |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 6256        |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003487054 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | 0.000582    |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 7001        |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010891107 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.78        |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -9.83e-05   |\n",
      "|    value_loss           | 65.7        |\n",
      "-----------------------------------------\n",
      "Logging to Training\\Logs\\RecurrentPPO_82\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 313    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 319    |\n",
      "|    total_timesteps | 100000 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 184          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1086         |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042263493 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.28         |\n",
      "|    n_updates            | 3420         |\n",
      "|    policy_gradient_loss | 0.000403     |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 161          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1853         |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034144109 |\n",
      "|    clip_fraction        | 0.00709      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | 0.000348     |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 2575         |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048570973 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.65         |\n",
      "|    n_updates            | 3460         |\n",
      "|    policy_gradient_loss | 0.000518     |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 3314         |\n",
      "|    total_timesteps      | 500000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030050725 |\n",
      "|    clip_fraction        | 0.00579      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.11         |\n",
      "|    n_updates            | 3480         |\n",
      "|    policy_gradient_loss | -0.000311    |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4065        |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005846392 |\n",
      "|    clip_fraction        | 0.00595     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | 0.000323    |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 4801        |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006527073 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.28        |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | 0.000266    |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 144          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 5517         |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068786917 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.86         |\n",
      "|    n_updates            | 3540         |\n",
      "|    policy_gradient_loss | 3e-05        |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 6254        |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008772019 |\n",
      "|    clip_fraction        | 0.011       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.000154   |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 142          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 6995         |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044863936 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.99         |\n",
      "|    n_updates            | 3580         |\n",
      "|    policy_gradient_loss | 0.000763     |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "Logging to Training\\Logs\\RecurrentPPO_83\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 312    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 319    |\n",
      "|    total_timesteps | 100000 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1056        |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014249506 |\n",
      "|    clip_fraction        | 0.0279      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.07        |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 167          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1788         |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045442004 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.21         |\n",
      "|    n_updates            | 3640         |\n",
      "|    policy_gradient_loss | 0.000127     |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2529        |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003216093 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -8.41e-05   |\n",
      "|    value_loss           | 84.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 3263         |\n",
      "|    total_timesteps      | 500000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048182462 |\n",
      "|    clip_fraction        | 0.00973      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 3680         |\n",
      "|    policy_gradient_loss | -0.000365    |\n",
      "|    value_loss           | 52           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 4013         |\n",
      "|    total_timesteps      | 600000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034204966 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.85         |\n",
      "|    n_updates            | 3700         |\n",
      "|    policy_gradient_loss | 6.67e-05     |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 146          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 4764         |\n",
      "|    total_timesteps      | 700000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031990483 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.7         |\n",
      "|    n_updates            | 3720         |\n",
      "|    policy_gradient_loss | -0.000402    |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 5518        |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007217454 |\n",
      "|    clip_fraction        | 0.00732     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -2.95e-05   |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 142          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 6298         |\n",
      "|    total_timesteps      | 900000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066020917 |\n",
      "|    clip_fraction        | 0.00756      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 3760         |\n",
      "|    policy_gradient_loss | -0.000309    |\n",
      "|    value_loss           | 77.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 141          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 7068         |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028817598 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 3780         |\n",
      "|    policy_gradient_loss | -0.000342    |\n",
      "|    value_loss           | 70.1         |\n",
      "------------------------------------------\n",
      "Logging to Training\\Logs\\RecurrentPPO_84\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 313    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 319    |\n",
      "|    total_timesteps | 100000 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 182         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1098        |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004749881 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.37        |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | 7.49e-05    |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 162          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1847         |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062704245 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.217        |\n",
      "|    n_updates            | 3840         |\n",
      "|    policy_gradient_loss | 8.31e-05     |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2583        |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005160978 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.3        |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | 9.28e-05    |\n",
      "|    value_loss           | 62.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3323        |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008780214 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | 0.000419    |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 147          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 4055         |\n",
      "|    total_timesteps      | 600000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047479398 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.975       |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 3900         |\n",
      "|    policy_gradient_loss | -4.33e-05    |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 146          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 4791         |\n",
      "|    total_timesteps      | 700000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011875443 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.997       |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.5         |\n",
      "|    n_updates            | 3920         |\n",
      "|    policy_gradient_loss | 0.000276     |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 5530        |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005749921 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.000312   |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 143          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 6281         |\n",
      "|    total_timesteps      | 900000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076513365 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.64         |\n",
      "|    n_updates            | 3960         |\n",
      "|    policy_gradient_loss | -0.000144    |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 142          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 7017         |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031307756 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.725        |\n",
      "|    n_updates            | 3980         |\n",
      "|    policy_gradient_loss | 0.00036      |\n",
      "|    value_loss           | 85.7         |\n",
      "------------------------------------------\n",
      "Logging to Training\\Logs\\RecurrentPPO_85\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 312    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 319    |\n",
      "|    total_timesteps | 100000 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 189          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1053         |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053465506 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.621        |\n",
      "|    n_updates            | 4020         |\n",
      "|    policy_gradient_loss | -0.000511    |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m RecurrentPPO\u001b[38;5;241m.\u001b[39mload(PPO_Path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewApproachItter2_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i), env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, tensorboard_log\u001b[38;5;241m=\u001b[39mlog_path, ent_coef\u001b[38;5;241m=\u001b[39ment_coef, \n\u001b[0;32m      7\u001b[0m                     n_steps\u001b[38;5;241m=\u001b[39mn_steps, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, n_epochs\u001b[38;5;241m=\u001b[39mn_epochs, \n\u001b[0;32m      8\u001b[0m                     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.5e-4\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m, gae_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m, vf_coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \n\u001b[0;32m      9\u001b[0m                     max_grad_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, clip_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10_000\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMULTIPLIER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39msave(PPO_Path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewApproachItter2_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\sb3_contrib\\ppo_recurrent\\ppo_recurrent.py:469\u001b[0m, in \u001b[0;36mRecurrentPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    466\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 469\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    472\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\sb3_contrib\\ppo_recurrent\\ppo_recurrent.py:244\u001b[0m, in \u001b[0;36mRecurrentPPO.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    242\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    243\u001b[0m     episode_starts \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts, dtype\u001b[38;5;241m=\u001b[39mth\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 244\u001b[0m     actions, values, log_probs, lstm_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_starts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\sb3_contrib\\common\\recurrent\\policies.py:249\u001b[0m, in \u001b[0;36mRecurrentActorCriticPolicy.forward\u001b[1;34m(self, obs, lstm_states, episode_starts, deterministic)\u001b[0m\n\u001b[0;32m    246\u001b[0m     latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(vf_features)\n\u001b[0;32m    247\u001b[0m     lstm_states_vf \u001b[38;5;241m=\u001b[39m lstm_states_pi\n\u001b[1;32m--> 249\u001b[0m latent_pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_critic(latent_vf)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:225\u001b[0m, in \u001b[0;36mMlpExtractor.forward_actor\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:101\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\DARVIN\\AICore\\.conda\\Lib\\site-packages\\torch\\nn\\functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "max_steps_callback = StopTrainingOnMaxSteps(max_steps=len(df_raw)-1)\n",
    "\n",
    "for i in range(10, 100):\n",
    "    if(i != 0):\n",
    "        model = RecurrentPPO.load(PPO_Path+\"newApproachItter2_\" + str(i), env, verbose=1, tensorboard_log=log_path, ent_coef=ent_coef, \n",
    "                        n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs, \n",
    "                        learning_rate=2.5e-4, gamma=0.99, gae_lambda=0.95, vf_coef=0.5, \n",
    "                        max_grad_norm=0.5, clip_range=0.2, policy_kwargs=policy_kwargs)\n",
    "    model.learn(total_timesteps=100_000 * MULTIPLIER, callback=max_steps_callback)\n",
    "    model.save(PPO_Path+\"newApproachItter2_\" + str(i+1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentPPO.load(PPO_Path+\"newApproachItter2_10\" , env, verbose=1, tensorboard_log=log_path, ent_coef=ent_coef, \n",
    "                        n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs, \n",
    "                        learning_rate=2.5e-4, gamma=0.99, gae_lambda=0.95, vf_coef=0.5, \n",
    "                        max_grad_norm=0.5, clip_range=0.2, policy_kwargs=policy_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position Opened: Type: short, Entry Price: 42445.11, Step: 0\n",
      "Position Closed: Exit Price: 42542.44, Close Step: 126, Time in Position: 126, Return from Last Trade: -25.137713036908508\n",
      "Position Opened: Type: short, Entry Price: 42573.99, Step: 130\n",
      "Position Closed: Exit Price: 42541.1, Close Step: 152, Time in Position: 22, Return from Last Trade: 2.4528366967717794\n",
      "Position Opened: Type: short, Entry Price: 42534.58, Step: 153\n",
      "Position Closed: Exit Price: 40858.27, Close Step: 11464, Time in Position: 11311, Return from Last Trade: 350.1946978199865\n",
      "Position Opened: Type: long, Entry Price: 40876.08, Step: 11465\n",
      "Position Closed: Exit Price: 41981.98, Close Step: 12023, Time in Position: 558, Return from Last Trade: 238.9944838154738\n",
      "Position Opened: Type: long, Entry Price: 41979.89, Step: 12024\n",
      "Position Closed: Exit Price: 41863.35, Close Step: 12204, Time in Position: 180, Return from Last Trade: -29.484820112677948\n",
      "Position Opened: Type: short, Entry Price: 41856.59, Step: 12205\n",
      "Position Closed: Exit Price: 41831.05, Close Step: 12347, Time in Position: 142, Return from Last Trade: 0.991608370389045\n",
      "Position Opened: Type: short, Entry Price: 41840.0, Step: 12348\n",
      "Position Closed: Exit Price: 41848.74, Close Step: 12515, Time in Position: 167, Return from Last Trade: -6.380019120458453\n",
      "Position Opened: Type: long, Entry Price: 41848.74, Step: 12517\n",
      "Position Closed: Exit Price: 41602.91, Close Step: 12710, Time in Position: 193, Return from Last Trade: -57.36825839917642\n",
      "Position Opened: Type: long, Entry Price: 41582.01, Step: 12711\n",
      "Position Closed: Exit Price: 41602.91, Close Step: 12724, Time in Position: 13, Return from Last Trade: 0.023590850947635467\n",
      "Position Opened: Type: long, Entry Price: 41613.11, Step: 12728\n",
      "Position Closed: Exit Price: 44841.17, Close Step: 30140, Time in Position: 17412, Return from Last Trade: 693.6583448100846\n",
      "Position Opened: Type: long, Entry Price: 44836.2, Step: 30141\n",
      "Position Closed: Exit Price: 48111.21, Close Step: 34441, Time in Position: 4300, Return from Last Trade: 652.8949174996993\n",
      "Position Opened: Type: short, Entry Price: 48104.0, Step: 34442\n",
      "Position Closed: Exit Price: 48182.0, Close Step: 34477, Time in Position: 35, Return from Last Trade: -19.093381007816397\n",
      "Position Opened: Type: long, Entry Price: 48180.95, Step: 34480\n",
      "Position Closed: Exit Price: 48216.01, Close Step: 34888, Time in Position: 408, Return from Last Trade: 2.049061402899788\n",
      "Position Opened: Type: long, Entry Price: 48230.81, Step: 34889\n",
      "Position Closed: Exit Price: 48163.67, Close Step: 34929, Time in Position: 40, Return from Last Trade: -17.028506156127065\n",
      "Position Opened: Type: short, Entry Price: 48151.33, Step: 34930\n",
      "Position Closed: Exit Price: 48281.99, Close Step: 34993, Time in Position: 63, Return from Last Trade: -28.921755328460623\n",
      "Position Opened: Type: short, Entry Price: 48282.03, Step: 34994\n",
      "Position Closed: Exit Price: 48116.0, Close Step: 35124, Time in Position: 130, Return from Last Trade: 26.448781565315077\n",
      "Position Opened: Type: long, Entry Price: 48106.0, Step: 35125\n",
      "Position Closed: Exit Price: 48115.51, Close Step: 35132, Time in Position: 7, Return from Last Trade: -2.7208040577055184\n",
      "Position Opened: Type: short, Entry Price: 48121.14, Step: 35133\n",
      "Position Closed: Exit Price: 48226.46, Close Step: 35153, Time in Position: 20, Return from Last Trade: -24.197787708271196\n",
      "Position Opened: Type: long, Entry Price: 48189.67, Step: 35154\n",
      "Position Closed: Exit Price: 48175.59, Close Step: 35172, Time in Position: 18, Return from Last Trade: -7.129609208778888\n",
      "Position Opened: Type: short, Entry Price: 48175.58, Step: 35175\n",
      "Position Closed: Exit Price: 48064.4, Close Step: 35202, Time in Position: 27, Return from Last Trade: 16.270274068314333\n",
      "Position Opened: Type: long, Entry Price: 48084.25, Step: 35203\n",
      "Position Closed: Exit Price: 48155.94, Close Step: 35228, Time in Position: 25, Return from Last Trade: 8.918323047567986\n",
      "Position Opened: Type: short, Entry Price: 48149.73, Step: 35229\n",
      "Position Closed: Exit Price: 48473.68, Close Step: 35361, Time in Position: 132, Return from Last Trade: -65.05174141163354\n",
      "Position Opened: Type: short, Entry Price: 48489.5, Step: 35362\n",
      "Position Closed: Exit Price: 48422.69, Close Step: 35374, Time in Position: 12, Return from Last Trade: 7.900416585033442\n",
      "Position Opened: Type: short, Entry Price: 48418.53, Step: 35376\n",
      "Position Closed: Exit Price: 48413.68, Close Step: 35378, Time in Position: 2, Return from Last Trade: -3.598485641757672\n",
      "Position Opened: Type: long, Entry Price: 48394.93, Step: 35380\n",
      "Position Closed: Exit Price: 48115.59, Close Step: 35443, Time in Position: 63, Return from Last Trade: -56.44883017704611\n",
      "Position Opened: Type: short, Entry Price: 48128.52, Step: 35445\n",
      "Position Closed: Exit Price: 48089.1, Close Step: 35521, Time in Position: 76, Return from Last Trade: 2.8715127745458267\n",
      "Position Opened: Type: long, Entry Price: 48115.04, Step: 35522\n",
      "Position Closed: Exit Price: 48102.06, Close Step: 35527, Time in Position: 5, Return from Last Trade: -6.927931058563576\n",
      "Position Opened: Type: long, Entry Price: 48087.99, Step: 35530\n",
      "Position Closed: Exit Price: 48210.72, Close Step: 35726, Time in Position: 196, Return from Last Trade: 18.469768543040143\n",
      "Position Opened: Type: short, Entry Price: 48216.96, Step: 35727\n",
      "Position Closed: Exit Price: 47866.96, Close Step: 35837, Time in Position: 110, Return from Last Trade: 60.829709712101305\n",
      "Position Opened: Type: short, Entry Price: 47908.0, Step: 35839\n",
      "Position Closed: Exit Price: 47957.2, Close Step: 35856, Time in Position: 17, Return from Last Trade: -13.742715204140724\n",
      "Position Opened: Type: short, Entry Price: 47969.54, Step: 35858\n",
      "Position Closed: Exit Price: 47833.14, Close Step: 35915, Time in Position: 57, Return from Last Trade: 21.091239774240343\n",
      "Position Opened: Type: long, Entry Price: 47849.61, Step: 35916\n",
      "Position Closed: Exit Price: 51913.99, Close Step: 41100, Time in Position: 5184, Return from Last Trade: 759.9664188485544\n",
      "Position Opened: Type: short, Entry Price: 51991.07, Step: 41105\n",
      "Position Closed: Exit Price: 52129.99, Close Step: 41136, Time in Position: 31, Return from Last Trade: -28.547975931250967\n",
      "Position Opened: Type: short, Entry Price: 52113.99, Step: 41138\n",
      "Position Closed: Exit Price: 51829.9, Close Step: 41464, Time in Position: 326, Return from Last Trade: 44.56187378859244\n",
      "Position Opened: Type: long, Entry Price: 51829.62, Step: 41465\n",
      "Position Closed: Exit Price: 51789.86, Close Step: 41541, Time in Position: 76, Return from Last Trade: -11.404160208004967\n",
      "Position Opened: Type: short, Entry Price: 51788.63, Step: 41542\n",
      "Position Closed: Exit Price: 52297.34, Close Step: 41753, Time in Position: 211, Return from Last Trade: -92.90531213125337\n",
      "Position Opened: Type: short, Entry Price: 52296.0, Step: 41754\n",
      "Position Closed: Exit Price: 52357.77, Close Step: 41775, Time in Position: 21, Return from Last Trade: -15.130449747590086\n",
      "Position Opened: Type: short, Entry Price: 52399.99, Step: 41777\n",
      "Position Closed: Exit Price: 52068.9, Close Step: 42022, Time in Position: 245, Return from Last Trade: 52.36661390584175\n",
      "Position Opened: Type: short, Entry Price: 52032.3, Step: 42023\n",
      "Position Closed: Exit Price: 52134.88, Close Step: 42418, Time in Position: 395, Return from Last Trade: -22.243209506401797\n",
      "Position Opened: Type: short, Entry Price: 52138.46, Step: 42422\n",
      "Position Closed: Exit Price: 51949.99, Close Step: 42518, Time in Position: 96, Return from Last Trade: 28.033181839279685\n",
      "Position Opened: Type: short, Entry Price: 51948.01, Step: 42519\n",
      "Position Closed: Exit Price: 51956.0, Close Step: 42570, Time in Position: 51, Return from Last Trade: -5.884268617796556\n",
      "Position Opened: Type: short, Entry Price: 51997.22, Step: 42571\n",
      "Position Closed: Exit Price: 51982.04, Close Step: 42580, Time in Position: 9, Return from Last Trade: -1.8725518402714103\n",
      "Position Opened: Type: long, Entry Price: 51959.46, Step: 42582\n",
      "Position Closed: Exit Price: 51884.92, Close Step: 42764, Time in Position: 182, Return from Last Trade: -17.41121963161295\n",
      "Position Opened: Type: short, Entry Price: 51827.27, Step: 42766\n",
      "Position Closed: Exit Price: 51923.1, Close Step: 42804, Time in Position: 38, Return from Last Trade: -21.141239254933087\n",
      "Position Opened: Type: short, Entry Price: 51919.79, Step: 42805\n",
      "Position Closed: Exit Price: 51589.42, Close Step: 43060, Time in Position: 255, Return from Last Trade: 52.76775859455563\n",
      "Position Opened: Type: long, Entry Price: 51550.0, Step: 43061\n",
      "Position Closed: Exit Price: 51659.22, Close Step: 43175, Time in Position: 114, Return from Last Trade: 14.568477206595745\n",
      "Position Opened: Type: long, Entry Price: 51661.1, Step: 43176\n",
      "Position Closed: Exit Price: 51307.72, Close Step: 43256, Time in Position: 80, Return from Last Trade: -66.06314906186621\n",
      "Position Opened: Type: long, Entry Price: 51273.7, Step: 43257\n",
      "Position Closed: Exit Price: 50875.23, Close Step: 43334, Time in Position: 77, Return from Last Trade: -74.4428751972248\n",
      "Position Opened: Type: short, Entry Price: 50888.86, Step: 43335\n",
      "Position Closed: Exit Price: 50798.0, Close Step: 43419, Time in Position: 84, Return from Last Trade: 11.569135759771495\n",
      "Position Opened: Type: long, Entry Price: 50784.0, Step: 43422\n",
      "Position Closed: Exit Price: 50919.98, Close Step: 43439, Time in Position: 17, Return from Last Trade: 19.59853497164518\n",
      "Position Opened: Type: long, Entry Price: 50928.81, Step: 43440\n",
      "Position Closed: Exit Price: 50823.63, Close Step: 48920, Time in Position: 5480, Return from Last Trade: -23.087121906048907\n",
      "Position Opened: Type: short, Entry Price: 50916.01, Step: 48923\n",
      "Position Closed: Exit Price: 51246.58, Close Step: 48995, Time in Position: 72, Return from Last Trade: -62.93211202134648\n",
      "Position Opened: Type: long, Entry Price: 51200.0, Step: 48996\n",
      "Position Closed: Exit Price: 50925.99, Close Step: 49091, Time in Position: 95, Return from Last Trade: -52.66582031250036\n",
      "Position Opened: Type: long, Entry Price: 50881.21, Step: 49092\n",
      "Position Closed: Exit Price: 50905.49, Close Step: 49308, Time in Position: 216, Return from Last Trade: -0.20529081364241275\n",
      "Position Opened: Type: long, Entry Price: 50904.0, Step: 49309\n",
      "Position Closed: Exit Price: 50941.96, Close Step: 49343, Time in Position: 34, Return from Last Trade: 2.211456859971557\n",
      "Position Opened: Type: short, Entry Price: 50910.2, Step: 49344\n",
      "Position Closed: Exit Price: 51334.01, Close Step: 49509, Time in Position: 165, Return from Last Trade: -79.42192134385732\n",
      "Position Opened: Type: long, Entry Price: 51313.71, Step: 49510\n",
      "Position Closed: Exit Price: 51288.42, Close Step: 51073, Time in Position: 1563, Return from Last Trade: -8.9356566695335\n",
      "Position Opened: Type: short, Entry Price: 51286.0, Step: 51074\n",
      "Position Closed: Exit Price: 51526.21, Close Step: 51171, Time in Position: 97, Return from Last Trade: -46.653609172093596\n",
      "Position Opened: Type: short, Entry Price: 51506.99, Step: 51173\n",
      "Position Closed: Exit Price: 51377.16, Close Step: 51184, Time in Position: 11, Return from Last Trade: 18.18565878145763\n",
      "Position Opened: Type: long, Entry Price: 51351.11, Step: 51189\n",
      "Position Closed: Exit Price: 51198.3, Close Step: 51377, Time in Position: 188, Return from Last Trade: -31.28208903371279\n",
      "Position Opened: Type: short, Entry Price: 51165.04, Step: 51379\n",
      "Position Closed: Exit Price: 51126.0, Close Step: 51424, Time in Position: 45, Return from Last Trade: 2.3671890024909166\n",
      "Position Opened: Type: short, Entry Price: 51196.59, Step: 51429\n",
      "Position Closed: Exit Price: 51168.23, Close Step: 51567, Time in Position: 138, Return from Last Trade: 0.4854882913088501\n",
      "Position Opened: Type: long, Entry Price: 51106.47, Step: 51568\n",
      "Position Closed: Exit Price: 51026.26, Close Step: 51646, Time in Position: 78, Return from Last Trade: -18.6252174137637\n",
      "Position Opened: Type: long, Entry Price: 51003.35, Step: 51647\n",
      "Position Closed: Exit Price: 51019.45, Close Step: 51926, Time in Position: 279, Return from Last Trade: -1.6590101434516185\n",
      "Position Opened: Type: short, Entry Price: 50980.61, Step: 51928\n",
      "Position Closed: Exit Price: 51130.67, Close Step: 52264, Time in Position: 336, Return from Last Trade: -30.991248339319185\n",
      "Position Opened: Type: long, Entry Price: 51098.15, Step: 52265\n",
      "Position Closed: Exit Price: 51113.44, Close Step: 52288, Time in Position: 23, Return from Last Trade: -1.8069475117982186\n",
      "Position Opened: Type: long, Entry Price: 51077.36, Step: 52289\n",
      "Position Closed: Exit Price: 50869.99, Close Step: 52554, Time in Position: 265, Return from Last Trade: -41.03928080856222\n",
      "Position Opened: Type: long, Entry Price: 50870.04, Step: 52555\n",
      "Position Closed: Exit Price: 50751.48, Close Step: 52701, Time in Position: 146, Return from Last Trade: -25.475804225826813\n",
      "Position Opened: Type: short, Entry Price: 50754.26, Step: 52703\n",
      "Position Closed: Exit Price: 50800.0, Close Step: 52732, Time in Position: 29, Return from Last Trade: -12.610846261968584\n",
      "Position Opened: Type: short, Entry Price: 50818.15, Step: 52733\n",
      "Position Closed: Exit Price: 50980.02, Close Step: 52816, Time in Position: 83, Return from Last Trade: -33.167513476975415\n",
      "Position Opened: Type: short, Entry Price: 50984.59, Step: 52818\n",
      "Position Closed: Exit Price: 51056.73, Close Step: 52863, Time in Position: 45, Return from Last Trade: -17.23443603253572\n",
      "Position Opened: Type: long, Entry Price: 51061.35, Step: 52864\n",
      "Position Closed: Exit Price: 50948.01, Close Step: 52919, Time in Position: 55, Return from Last Trade: -24.477145140110252\n",
      "Position Opened: Type: short, Entry Price: 50968.68, Step: 52921\n",
      "Position Closed: Exit Price: 50969.1, Close Step: 52925, Time in Position: 4, Return from Last Trade: -4.574163191983475\n",
      "Position Opened: Type: short, Entry Price: 50969.09, Step: 52926\n",
      "Position Closed: Exit Price: 50952.92, Close Step: 52934, Time in Position: 8, Return from Last Trade: -1.644740076780176\n",
      "Position Opened: Type: long, Entry Price: 50938.93, Step: 52936\n",
      "Position Closed: Exit Price: 51120.79, Close Step: 56003, Time in Position: 3067, Return from Last Trade: 27.63141697322667\n",
      "Position Opened: Type: short, Entry Price: 51134.0, Step: 56004\n",
      "Position Closed: Exit Price: 51146.01, Close Step: 56147, Time in Position: 143, Return from Last Trade: -6.613857707201047\n",
      "Position Opened: Type: long, Entry Price: 51152.0, Step: 56148\n",
      "Position Closed: Exit Price: 56936.01, Close Step: 58170, Time in Position: 2022, Return from Last Trade: 1013.1745777291214\n",
      "Position Opened: Type: short, Entry Price: 56872.56, Step: 58171\n",
      "Position Closed: Exit Price: 57132.37, Close Step: 58556, Time in Position: 385, Return from Last Trade: -45.61455506838526\n",
      "Position Opened: Type: long, Entry Price: 57147.02, Step: 58559\n",
      "Position Closed: Exit Price: 61698.63, Close Step: 59885, Time in Position: 1326, Return from Last Trade: 712.3263542000967\n",
      "Position Opened: Type: long, Entry Price: 61740.29, Step: 59886\n",
      "Position Closed: Exit Price: 62065.54, Close Step: 60037, Time in Position: 151, Return from Last Trade: 42.91231374196656\n",
      "Position Opened: Type: short, Entry Price: 62000.01, Step: 60038\n",
      "Position Closed: Exit Price: 62436.23, Close Step: 60061, Time in Position: 23, Return from Last Trade: -67.82224785125051\n",
      "Position Opened: Type: long, Entry Price: 62489.99, Step: 60062\n",
      "Position Closed: Exit Price: 62850.0, Close Step: 60373, Time in Position: 311, Return from Last Trade: 47.349744255040186\n",
      "Position Opened: Type: long, Entry Price: 62873.7, Step: 60374\n",
      "Position Closed: Exit Price: 62944.0, Close Step: 60397, Time in Position: 23, Return from Last Trade: 5.563031124301993\n",
      "Position Opened: Type: long, Entry Price: 63023.65, Step: 60399\n",
      "Position Closed: Exit Price: 62762.54, Close Step: 60531, Time in Position: 132, Return from Last Trade: -41.78743098820848\n",
      "Position Opened: Type: long, Entry Price: 62692.96, Step: 60532\n",
      "Position Closed: Exit Price: 62901.11, Close Step: 60594, Time in Position: 62, Return from Last Trade: 25.381345529067588\n",
      "Position Opened: Type: short, Entry Price: 62814.02, Step: 60595\n",
      "Position Closed: Exit Price: 62354.64, Close Step: 61931, Time in Position: 1336, Return from Last Trade: 61.320019161327\n",
      "Position Opened: Type: long, Entry Price: 62310.0, Step: 61933\n",
      "Position Closed: Exit Price: 61806.28, Close Step: 62194, Time in Position: 261, Return from Last Trade: -77.25686085700546\n",
      "Position Opened: Type: long, Entry Price: 62047.91, Step: 62199\n",
      "Position Closed: Exit Price: 61909.98, Close Step: 62225, Time in Position: 26, Return from Last Trade: -24.506636806944865\n",
      "Position Opened: Type: long, Entry Price: 61896.71, Step: 62226\n",
      "Position Closed: Exit Price: 61978.43, Close Step: 62247, Time in Position: 21, Return from Last Trade: 7.382376300776091\n",
      "Position Opened: Type: short, Entry Price: 62020.05, Step: 62248\n",
      "Position Closed: Exit Price: 62421.99, Close Step: 62372, Time in Position: 124, Return from Last Trade: -62.827266746801314\n",
      "Position Opened: Type: short, Entry Price: 62492.01, Step: 62374\n",
      "Position Closed: Exit Price: 62396.0, Close Step: 62415, Time in Position: 41, Return from Last Trade: 9.327207670228853\n",
      "Position Opened: Type: short, Entry Price: 62524.5, Step: 62417\n",
      "Position Closed: Exit Price: 62142.64, Close Step: 62968, Time in Position: 551, Return from Last Trade: 50.46629321306057\n",
      "Position Opened: Type: long, Entry Price: 62173.52, Step: 62969\n",
      "Position Closed: Exit Price: 61977.34, Close Step: 63228, Time in Position: 259, Return from Last Trade: -32.89826344077032\n",
      "Position Opened: Type: long, Entry Price: 61936.0, Step: 63230\n",
      "Position Closed: Exit Price: 61975.81, Close Step: 63257, Time in Position: 27, Return from Last Trade: 1.2848424179795117\n",
      "Position Opened: Type: short, Entry Price: 61955.97, Step: 63258\n",
      "Position Closed: Exit Price: 61963.73, Close Step: 63327, Time in Position: 69, Return from Last Trade: -5.627252143740439\n",
      "Position Opened: Type: long, Entry Price: 61999.99, Step: 63330\n",
      "Position Closed: Exit Price: 62100.0, Close Step: 63341, Time in Position: 11, Return from Last Trade: 10.017582986707229\n",
      "Position Opened: Type: short, Entry Price: 62087.75, Step: 63344\n",
      "Position Closed: Exit Price: 61837.99, Close Step: 63559, Time in Position: 215, Return from Last Trade: 31.704243188068794\n",
      "Position Opened: Type: short, Entry Price: 61812.7, Step: 63561\n",
      "Position Closed: Exit Price: 61977.08, Close Step: 63719, Time in Position: 158, Return from Last Trade: -28.433916492889683\n",
      "Position Opened: Type: long, Entry Price: 61997.22, Step: 63723\n",
      "Position Closed: Exit Price: 62035.39, Close Step: 63988, Time in Position: 265, Return from Last Trade: 1.0410549053648586\n",
      "Position Opened: Type: long, Entry Price: 62048.92, Step: 63989\n",
      "Position Closed: Exit Price: 61790.17, Close Step: 64199, Time in Position: 210, Return from Last Trade: -42.03087080323074\n",
      "Position Opened: Type: long, Entry Price: 61790.17, Step: 64200\n",
      "Position Closed: Exit Price: 61961.11, Close Step: 64253, Time in Position: 53, Return from Last Trade: 20.398135091714767\n",
      "Position Opened: Type: short, Entry Price: 61997.99, Step: 64254\n",
      "Position Closed: Exit Price: 61920.48, Close Step: 64259, Time in Position: 5, Return from Last Trade: 6.751816389530578\n",
      "Position Opened: Type: short, Entry Price: 61923.79, Step: 64260\n",
      "Position Closed: Exit Price: 62048.05, Close Step: 64306, Time in Position: 46, Return from Last Trade: -22.559941098566775\n",
      "Position Opened: Type: short, Entry Price: 62050.57, Step: 64307\n",
      "Position Closed: Exit Price: 61875.9, Close Step: 64437, Time in Position: 130, Return from Last Trade: 20.83465848903538\n",
      "Position Opened: Type: short, Entry Price: 61865.01, Step: 64438\n",
      "Position Closed: Exit Price: 61732.47, Close Step: 64614, Time in Position: 176, Return from Last Trade: 14.78165856596496\n",
      "Position Opened: Type: short, Entry Price: 61739.99, Step: 64615\n",
      "Position Closed: Exit Price: 62787.66, Close Step: 65119, Time in Position: 504, Return from Last Trade: -157.22159908027277\n",
      "Position Opened: Type: long, Entry Price: 62763.79, Step: 65120\n",
      "Position Closed: Exit Price: 62744.42, Close Step: 65292, Time in Position: 172, Return from Last Trade: -7.277556932110435\n",
      "Position Opened: Type: short, Entry Price: 62736.59, Step: 65293\n",
      "Position Closed: Exit Price: 63193.8, Close Step: 65382, Time in Position: 89, Return from Last Trade: -70.08995316768186\n",
      "Position Opened: Type: long, Entry Price: 63185.06, Step: 65383\n",
      "Position Closed: Exit Price: 63406.04, Close Step: 65821, Time in Position: 438, Return from Last Trade: 26.976111599799523\n",
      "Position Opened: Type: short, Entry Price: 63358.0, Step: 65822\n",
      "Position Closed: Exit Price: 63658.27, Close Step: 65879, Time in Position: 57, Return from Last Trade: -47.1533350168877\n",
      "Position Opened: Type: long, Entry Price: 63665.87, Step: 65881\n",
      "Position Closed: Exit Price: 59952.89, Close Step: 68098, Time in Position: 2217, Return from Last Trade: -529.3780861708169\n",
      "Position Opened: Type: short, Entry Price: 61093.02, Step: 68099\n",
      "Position Closed: Exit Price: 64171.24, Close Step: 68327, Time in Position: 228, Return from Last Trade: -457.97209877658713\n",
      "Position Opened: Type: long, Entry Price: 64230.0, Step: 68328\n",
      "Position Closed: Exit Price: 63140.0, Close Step: 68562, Time in Position: 234, Return from Last Trade: -157.232368052312\n",
      "Position Opened: Type: short, Entry Price: 63096.74, Step: 68565\n",
      "Position Closed: Exit Price: 66087.21, Close Step: 68679, Time in Position: 114, Return from Last Trade: -431.05500109831473\n",
      "Position Opened: Type: short, Entry Price: 66113.5, Step: 68681\n",
      "Position Closed: Exit Price: 66072.44, Close Step: 68698, Time in Position: 17, Return from Last Trade: 1.0894786995088603\n",
      "Position Opened: Type: long, Entry Price: 66244.31, Step: 68699\n",
      "Position Closed: Exit Price: 66100.0, Close Step: 68776, Time in Position: 77, Return from Last Trade: -24.106061260204523\n",
      "Position Opened: Type: short, Entry Price: 66169.66, Step: 68777\n",
      "Position Closed: Exit Price: 66435.4, Close Step: 68970, Time in Position: 193, Return from Last Trade: -40.64435981686948\n",
      "Position Opened: Type: short, Entry Price: 66479.99, Step: 68971\n",
      "Position Closed: Exit Price: 66953.21, Close Step: 69043, Time in Position: 72, Return from Last Trade: -68.56408905897865\n",
      "Position Opened: Type: short, Entry Price: 66981.11, Step: 69046\n",
      "Position Closed: Exit Price: 66833.12, Close Step: 69220, Time in Position: 174, Return from Last Trade: 15.384860074729236\n",
      "Position Opened: Type: short, Entry Price: 67019.01, Step: 69221\n",
      "Position Closed: Exit Price: 66550.01, Close Step: 69279, Time in Position: 58, Return from Last Trade: 58.48212999565348\n",
      "Position Opened: Type: short, Entry Price: 66669.99, Step: 69280\n",
      "Position Closed: Exit Price: 66567.32, Close Step: 69629, Time in Position: 349, Return from Last Trade: 9.359759091009078\n",
      "Position Opened: Type: long, Entry Price: 66518.93, Step: 69631\n",
      "Position Closed: Exit Price: 66117.33, Close Step: 69955, Time in Position: 324, Return from Last Trade: -58.83641220626853\n",
      "Position Opened: Type: long, Entry Price: 66133.23, Step: 69956\n",
      "Position Closed: Exit Price: 72103.08, Close Step: 76761, Time in Position: 6805, Return from Last Trade: 807.9304528903255\n",
      "Position Opened: Type: long, Entry Price: 72147.09, Step: 76762\n",
      "Position Closed: Exit Price: 72174.0, Close Step: 76776, Time in Position: 14, Return from Last Trade: -1.1431078509191233\n",
      "Position Opened: Type: short, Entry Price: 72113.29, Step: 76778\n",
      "Position Closed: Exit Price: 72585.99, Close Step: 76897, Time in Position: 119, Return from Last Trade: -63.49467351995874\n",
      "Position Opened: Type: long, Entry Price: 72539.42, Step: 76898\n",
      "Position Closed: Exit Price: 71746.38, Close Step: 77190, Time in Position: 292, Return from Last Trade: -102.892846262073\n",
      "Position Opened: Type: short, Entry Price: 71777.42, Step: 77191\n",
      "Position Closed: Exit Price: 72166.66, Close Step: 77421, Time in Position: 230, Return from Last Trade: -53.30587794880405\n",
      "Position Opened: Type: short, Entry Price: 72136.06, Step: 77423\n",
      "Position Closed: Exit Price: 71670.25, Close Step: 77491, Time in Position: 68, Return from Last Trade: 53.61642609812594\n",
      "Position Opened: Type: long, Entry Price: 71666.36, Step: 77494\n",
      "Position Closed: Exit Price: 71951.91, Close Step: 77533, Time in Position: 39, Return from Last Trade: 31.35992088896417\n",
      "Position Opened: Type: long, Entry Price: 71889.78, Step: 77535\n",
      "Position Closed: Exit Price: 72171.07, Close Step: 77810, Time in Position: 275, Return from Last Trade: 30.715158538530424\n",
      "Position Opened: Type: long, Entry Price: 72228.72, Step: 77812\n",
      "Position Closed: Exit Price: 72018.36, Close Step: 77907, Time in Position: 95, Return from Last Trade: -30.71173405814204\n",
      "Position Opened: Type: short, Entry Price: 72068.04, Step: 77908\n",
      "Position Closed: Exit Price: 71363.02, Close Step: 78115, Time in Position: 207, Return from Last Trade: 83.54429813825804\n",
      "Position Opened: Type: short, Entry Price: 71445.34, Step: 78122\n",
      "Position Closed: Exit Price: 71092.03, Close Step: 78187, Time in Position: 65, Return from Last Trade: 40.00661162785396\n",
      "Position Opened: Type: short, Entry Price: 71110.08, Step: 78188\n",
      "Position Closed: Exit Price: 71139.6, Close Step: 78336, Time in Position: 148, Return from Last Trade: -8.236179174598547\n",
      "Position Opened: Type: long, Entry Price: 71249.56, Step: 78339\n",
      "Position Closed: Exit Price: 71170.96, Close Step: 78363, Time in Position: 24, Return from Last Trade: -14.42848236536368\n",
      "Position Opened: Type: short, Entry Price: 71141.35, Step: 78364\n",
      "Position Closed: Exit Price: 71470.81, Close Step: 78425, Time in Position: 61, Return from Last Trade: -46.17955766934316\n",
      "Position Opened: Type: long, Entry Price: 71473.86, Step: 78426\n",
      "Position Closed: Exit Price: 71895.4, Close Step: 78520, Time in Position: 94, Return from Last Trade: 48.58038491274911\n",
      "Position Opened: Type: long, Entry Price: 71850.01, Step: 78521\n",
      "Position Closed: Exit Price: 71860.14, Close Step: 78522, Time in Position: 1, Return from Last Trade: -3.2311066484188116\n",
      "Position Opened: Type: long, Entry Price: 71928.0, Step: 78524\n",
      "Position Closed: Exit Price: 71999.18, Close Step: 78656, Time in Position: 132, Return from Last Trade: 4.406406406405534\n",
      "Position Opened: Type: long, Entry Price: 71990.0, Step: 78657\n",
      "Position Closed: Exit Price: 71340.0, Close Step: 80869, Time in Position: 2212, Return from Last Trade: -85.76128628976247\n",
      "Position Opened: Type: short, Entry Price: 71276.57, Step: 80870\n",
      "Position Closed: Exit Price: 70767.99, Close Step: 80915, Time in Position: 45, Return from Last Trade: 59.71773662789913\n",
      "Position Opened: Type: long, Entry Price: 70812.0, Step: 80916\n",
      "Position Closed: Exit Price: 67195.58, Close Step: 81499, Time in Position: 583, Return from Last Trade: -464.1365022877476\n",
      "Position Opened: Type: long, Entry Price: 67439.25, Step: 81501\n",
      "Position Closed: Exit Price: 66930.0, Close Step: 81837, Time in Position: 336, Return from Last Trade: -72.46116504854368\n",
      "Position Opened: Type: short, Entry Price: 66503.8, Step: 81838\n",
      "Position Closed: Exit Price: 67031.99, Close Step: 81866, Time in Position: 28, Return from Last Trade: -75.98027631503795\n",
      "Position Opened: Type: short, Entry Price: 67247.88, Step: 81868\n",
      "Position Closed: Exit Price: 67483.59, Close Step: 81937, Time in Position: 69, Return from Last Trade: -36.045827169569165\n",
      "Position Opened: Type: short, Entry Price: 67681.11, Step: 81939\n",
      "Position Closed: Exit Price: 67357.52, Close Step: 81987, Time in Position: 48, Return from Last Trade: 38.52987938584294\n",
      "Position Opened: Type: short, Entry Price: 67465.83, Step: 81993\n",
      "Position Closed: Exit Price: 68516.35, Close Step: 82403, Time in Position: 410, Return from Last Trade: -144.64027545499755\n",
      "Position Opened: Type: short, Entry Price: 68579.23, Step: 82406\n",
      "Position Closed: Exit Price: 68159.96, Close Step: 82525, Time in Position: 119, Return from Last Trade: 50.52292749568501\n",
      "Position Opened: Type: short, Entry Price: 68213.05, Step: 82528\n",
      "Position Closed: Exit Price: 68068.97, Close Step: 82582, Time in Position: 54, Return from Last Trade: 14.509852220359821\n",
      "Position Opened: Type: long, Entry Price: 68141.08, Step: 82584\n",
      "Position Closed: Exit Price: 68340.0, Close Step: 82646, Time in Position: 62, Return from Last Trade: 21.773138024815342\n",
      "Position Opened: Type: long, Entry Price: 68353.16, Step: 82647\n",
      "Position Closed: Exit Price: 64910.0, Close Step: 84609, Time in Position: 1962, Return from Last Trade: -457.85782573914696\n",
      "Position Opened: Type: long, Entry Price: 64760.46, Step: 84611\n",
      "Position Closed: Exit Price: 65155.82, Close Step: 84616, Time in Position: 5, Return from Last Trade: 50.44463751492817\n",
      "Position Opened: Type: long, Entry Price: 65288.36, Step: 84619\n",
      "Position Closed: Exit Price: 65385.31, Close Step: 84621, Time in Position: 2, Return from Last Trade: 8.864556867410572\n",
      "Position Opened: Type: short, Entry Price: 65368.0, Step: 84622\n",
      "Position Closed: Exit Price: 66480.0, Close Step: 84716, Time in Position: 94, Return from Last Trade: -157.6024354424183\n",
      "Position Opened: Type: long, Entry Price: 66527.18, Step: 84718\n",
      "Position Closed: Exit Price: 67086.29, Close Step: 85022, Time in Position: 304, Return from Last Trade: 71.13810761255785\n",
      "Position Opened: Type: long, Entry Price: 67091.89, Step: 85024\n",
      "Position Closed: Exit Price: 67456.01, Close Step: 85683, Time in Position: 659, Return from Last Trade: 44.344651715728354\n",
      "Position Opened: Type: long, Entry Price: 67578.89, Step: 85685\n",
      "Position Closed: Exit Price: 67364.0, Close Step: 85700, Time in Position: 15, Return from Last Trade: -33.11855233194855\n",
      "Position Opened: Type: long, Entry Price: 67429.73, Step: 85702\n",
      "Position Closed: Exit Price: 67436.22, Close Step: 85765, Time in Position: 63, Return from Last Trade: -3.6337648838272503\n",
      "Position Opened: Type: short, Entry Price: 67474.99, Step: 85767\n",
      "Position Closed: Exit Price: 66842.21, Close Step: 86490, Time in Position: 723, Return from Last Trade: 79.90193914811975\n",
      "Position Opened: Type: long, Entry Price: 66973.07, Step: 86491\n",
      "Position Closed: Exit Price: 67124.13, Close Step: 86628, Time in Position: 137, Return from Last Trade: 15.799801099157897\n",
      "Position Opened: Type: long, Entry Price: 67055.4, Step: 86629\n",
      "Position Closed: Exit Price: 67064.92, Close Step: 86658, Time in Position: 29, Return from Last Trade: -3.2222505570015736\n",
      "Position Opened: Type: short, Entry Price: 67224.0, Step: 86663\n",
      "Position Closed: Exit Price: 66381.1, Close Step: 87134, Time in Position: 471, Return from Last Trade: 108.34808996786785\n",
      "Position Opened: Type: short, Entry Price: 66371.39, Step: 87137\n",
      "Position Closed: Exit Price: 67479.41, Close Step: 89730, Time in Position: 2593, Return from Last Trade: -154.74817168963972\n",
      "Position Opened: Type: short, Entry Price: 67470.01, Step: 89731\n",
      "Position Closed: Exit Price: 67501.11, Close Step: 89804, Time in Position: 73, Return from Last Trade: -8.648509834221937\n",
      "Position Opened: Type: long, Entry Price: 67636.11, Step: 89805\n",
      "Position Closed: Exit Price: 67851.09, Close Step: 89901, Time in Position: 96, Return from Last Trade: 24.10631695110738\n",
      "Position Opened: Type: short, Entry Price: 67803.98, Step: 89902\n",
      "Position Closed: Exit Price: 67649.77, Close Step: 90058, Time in Position: 156, Return from Last Trade: 15.969152400787195\n",
      "Position Opened: Type: long, Entry Price: 67700.0, Step: 90059\n",
      "Position Closed: Exit Price: 67658.56, Close Step: 90109, Time in Position: 50, Return from Last Trade: -10.00901033973443\n",
      "Position Opened: Type: short, Entry Price: 67660.01, Step: 90110\n",
      "Position Closed: Exit Price: 66980.0, Close Step: 90307, Time in Position: 197, Return from Last Trade: 85.95357811800433\n",
      "Position Opened: Type: short, Entry Price: 66952.46, Step: 90308\n",
      "Position Closed: Exit Price: 67377.82, Close Step: 90422, Time in Position: 114, Return from Last Trade: -61.67848156736892\n",
      "Position Opened: Type: long, Entry Price: 67538.67, Step: 90424\n",
      "Position Closed: Exit Price: 67554.1, Close Step: 90719, Time in Position: 295, Return from Last Trade: -2.443844615239416\n",
      "Position Opened: Type: long, Entry Price: 67487.94, Step: 90720\n",
      "Position Closed: Exit Price: 65400.0, Close Step: 91205, Time in Position: 485, Return from Last Trade: -282.9417482590226\n",
      "Position Opened: Type: short, Entry Price: 65410.55, Step: 91207\n",
      "Position Closed: Exit Price: 65398.9, Close Step: 91335, Time in Position: 128, Return from Last Trade: -2.8970475710720507\n",
      "Position Opened: Type: short, Entry Price: 65282.0, Step: 91336\n",
      "Position Closed: Exit Price: 65769.63, Close Step: 91451, Time in Position: 115, Return from Last Trade: -71.72634110474621\n",
      "Position Opened: Type: long, Entry Price: 65805.31, Step: 91452\n",
      "Position Closed: Exit Price: 65827.67, Close Step: 91631, Time in Position: 179, Return from Last Trade: -1.4418881242257617\n",
      "Position Opened: Type: short, Entry Price: 65880.0, Step: 91632\n",
      "Position Closed: Exit Price: 66470.95, Close Step: 91766, Time in Position: 134, Return from Last Trade: -85.2308743169395\n",
      "Position Opened: Type: long, Entry Price: 66420.0, Step: 91768\n",
      "Position Closed: Exit Price: 63079.13, Close Step: 92201, Time in Position: 433, Return from Last Trade: -457.19241192411954\n",
      "Position Opened: Type: short, Entry Price: 63027.96, Step: 92202\n",
      "Position Closed: Exit Price: 63305.69, Close Step: 92279, Time in Position: 77, Return from Last Trade: -44.15811363718624\n",
      "Position Opened: Type: long, Entry Price: 63633.62, Step: 92286\n",
      "Position Closed: Exit Price: 63366.18, Close Step: 92629, Time in Position: 343, Return from Last Trade: -42.325287953129504\n",
      "Position Opened: Type: short, Entry Price: 63334.13, Step: 92631\n",
      "Position Closed: Exit Price: 62918.0, Close Step: 92680, Time in Position: 49, Return from Last Trade: 54.63351932046713\n",
      "Position Opened: Type: long, Entry Price: 62910.0, Step: 92682\n",
      "Position Closed: Exit Price: 63143.15, Close Step: 92718, Time in Position: 36, Return from Last Trade: 28.854792560801357\n",
      "Position Opened: Type: long, Entry Price: 63054.25, Step: 92719\n",
      "Position Closed: Exit Price: 63092.26, Close Step: 92729, Time in Position: 10, Return from Last Trade: 0.92532818961479\n",
      "Position Opened: Type: long, Entry Price: 63138.01, Step: 92731\n",
      "Episode: 0 Score: 195031.75885407627 Current Capital: 10376.37581005201 Sharpe Ratio: 1.9438248036573043 Current step: 99999 Trades amount: 181\n"
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "\n",
    "for episode in range(0, episodes):\n",
    "    obs = env.reset()\n",
    "    lstm_states = None  # Initialize LSTM states\n",
    "    episode_starts = np.ones((1,), dtype=bool)  # Initialize episode starts\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render(mode=\"human\")\n",
    "        action, lstm_states = model.predict(obs, state=lstm_states, episode_start=episode_starts)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        episode_starts = dones\n",
    "        done = dones[0]  # Update done status based on the environment\n",
    "        score += rewards[0]\n",
    "    env_info = info[0]\n",
    "    current_capital = env_info.get('current_capital', 'N/A')\n",
    "    sharpe_ratio = env_info.get('sharpe_ratio', 'N/A')\n",
    "    current_step = env_info.get('current_step', 'N/A')\n",
    "    trades_amount = env_info.get('trades_amount', 'N/A')\n",
    "    trade_details = env_info.get('trade_details', 'N/A')\n",
    "    print(f'Episode: {episode} Score: {score} Current Capital: {current_capital} Sharpe Ratio: {sharpe_ratio} Current step: {current_step} Trades amount: {trades_amount}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_trading_results_with_candles_interactive(df_raw, trade_details, capital_history, padding=10):\n",
    "    # Convert to the required format for candlestick chart\n",
    "    df_candle = df_raw[['open', 'high', 'low', 'close']]\n",
    "    \n",
    "    # Create the candlestick figure\n",
    "    fig = go.Figure(data=[go.Candlestick(x=df_candle.index,\n",
    "                                         open=df_candle['open'],\n",
    "                                         high=df_candle['high'],\n",
    "                                         low=df_candle['low'],\n",
    "                                         close=df_candle['close'],\n",
    "                                         name='Candlestick')])\n",
    "\n",
    "    # Keep track of the legend names we've added to ensure they are unique\n",
    "    legend_names = set()\n",
    "\n",
    "    # Add buy (green) and sell (red) markers\n",
    "    for i, trade in enumerate(trade_details):\n",
    "        trade_type = trade['type']\n",
    "        action = trade['action']\n",
    "        step = trade['step']\n",
    "        if action == 'open' and trade_type == 'long':\n",
    "            legend_name = f'Buy (Long)'\n",
    "            y_position = df_raw.loc[step, 'low'] - padding\n",
    "        elif action == 'open' and trade_type == 'short':\n",
    "            legend_name = f'Sell (Short)'\n",
    "            y_position = df_raw.loc[step, 'high'] + padding\n",
    "        elif action == 'close':\n",
    "            legend_name = f'Close'\n",
    "            y_position = trade['price']\n",
    "\n",
    "        if legend_name not in legend_names:\n",
    "            show_legend = True\n",
    "            legend_names.add(legend_name)\n",
    "        else:\n",
    "            show_legend = False\n",
    "        \n",
    "        marker_symbol = 'triangle-up' if trade_type == 'long' else 'triangle-down'\n",
    "        marker_color = 'green' if trade_type == 'long' else 'red'\n",
    "        if action == 'close':\n",
    "            marker_symbol = 'circle'\n",
    "            marker_color = 'blue'\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[df_raw.index[step]], y=[y_position],\n",
    "            mode='markers', name=legend_name,\n",
    "            marker=dict(color=marker_color, size=10, symbol=marker_symbol),\n",
    "            showlegend=show_legend\n",
    "        ))\n",
    "\n",
    "    # Trace for capital history\n",
    "    capital_trace = go.Scatter(\n",
    "        x=capital_history['step'],\n",
    "        y=capital_history['capital'],\n",
    "        mode='lines+markers',\n",
    "        name='Capital Over Time',\n",
    "        yaxis='y2'\n",
    "    )\n",
    "    fig.add_trace(capital_trace)\n",
    "\n",
    "    # Update layout to add a secondary y-axis for the capital\n",
    "    fig.update_layout(\n",
    "        title='Trading Strategy Results',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price',\n",
    "        yaxis2=dict(\n",
    "            title='Capital',\n",
    "            overlaying='y',\n",
    "            side='right',\n",
    "            showgrid=False\n",
    "        ),\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        width=1920,\n",
    "        height=1000,\n",
    "        margin=dict(l=50, r=50, t=50, b=50)\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "# This code will handle legend names correctly in the Plotly figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_capital_over_time(df_raw, trade_details, initial_capital=10000):\n",
    "    capital_over_time = [initial_capital]\n",
    "    \n",
    "    for step in range(len(df_raw)):\n",
    "        trade = next((trade for trade in trade_details if trade['step'] == step), None)\n",
    "        if trade:\n",
    "            new_capital = trade['capital']\n",
    "        else:\n",
    "            new_capital = capital_over_time[-1]\n",
    "        capital_over_time.append(new_capital)\n",
    "\n",
    "    # Creating a DataFrame for capital history\n",
    "    capital_history = pd.DataFrame({\n",
    "        'step': list(range(len(capital_over_time))),\n",
    "        'capital': capital_over_time\n",
    "    })\n",
    "\n",
    "    return capital_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "plot_trading_results_with_candles_interactive(df_raw, trade_details, calculate_capital_over_time(df_raw, trade_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "env.reset()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=20, deterministic= False)\n",
    "print(f'Mean Reward: {mean_reward}, Std Reward: {std_reward}')\n",
    "\n",
    "# Close the environments\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_log_path = os.path.join(log_path, 'PPO_6')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from websocket._app import WebSocketApp\n",
    "# import json\n",
    "\n",
    "# def on_message(ws, message):\n",
    "#     data = json.loads(message)\n",
    "#     # Check if the candle is closed\n",
    "#     if data['k']['x']:\n",
    "#         print(f\"Candle closed data: {data}\")\n",
    "\n",
    "# def on_error(ws, error):\n",
    "#     print(f\"Error: {error}\")\n",
    "    \n",
    "# def on_close(ws, close_status_code, close_msg):\n",
    "#     print(\"Connection closed\")\n",
    "\n",
    "# def on_open(ws):\n",
    "#     print(\"Connection opened\")\n",
    "\n",
    "# # Setup WebSocket connection\n",
    "# ws = WebSocketApp(\"wss://stream.binance.com:9443/ws/btcusdt@kline_1m\",\n",
    "#                             on_open=on_open,\n",
    "#                             on_message=on_message,\n",
    "#                             on_error=on_error,\n",
    "#                             on_close=on_close)\n",
    "\n",
    "# # Run the WebSocket client\n",
    "# ws.run_forever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from binance.client import Client\n",
    "# import datetime\n",
    "\n",
    "# # Initialize the Binance Client\n",
    "# client = Client()\n",
    "\n",
    "# # Define the symbol and interval\n",
    "# symbol = 'BTCUSDT'\n",
    "# interval = '1m'\n",
    "\n",
    "# # Calculate the start time (1000 minutes ago)\n",
    "# end_time = datetime.datetime.now()\n",
    "# start_time = end_time - datetime.timedelta(minutes=1000)\n",
    "\n",
    "# # Request historical klines\n",
    "# klines = client.get_historical_klines(symbol, interval, start_time.strftime(\"%d %b, %Y %H:%M:%S\"), end_time.strftime(\"%d %b, %Y %H:%M:%S\"))\n",
    "# #Open time, Open, High, Low, Close, Volume, Close time, Quote asset volume, Number of trades, Taker buy base asset volume, Taker buy quote asset volume, Ignore)\n",
    "\n",
    "\n",
    "# # Print the results\n",
    "# for kline in klines:\n",
    "#     print(kline)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
